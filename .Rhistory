colnames(allmet) <- cn;rm(cn)
#+
Prec.dat <- dailyCFSRvals(CFSR.dat=allmet,FUN=c("sum"),varname='pre')
#Prec.dat <- dailyCFSRvals(CFSR.dat=Prec.dat,FUN="sum")
Prec.dat.d <- cbind.data.frame(Prec.dat,days.since.base(Prec.dat$imdate,baseline="-11-01"))
Prec.dat.d <- cbind.data.frame(Prec.dat.d,Cumvals.dailyCFSR(Prec.dat.d,"pre"))
#code to run on summarized winter data
#+++++++++++ functions to perform and analyze Tukey test  +++++++++++####
plot.CFSR.Annual.var <- function(df,maxday=150,varname,maxbaseyr=2011){
ss<-which((df$BaseYear >1999)&(df$DOYsinceBase < maxday)&(df$BaseYear <= maxbaseyr))
win.graph(width=9,h=5)
plot(as.factor(df$BaseYear[ss]),df[[varname]][ss],ylab=varname,col="grey")
Tukeytab <- TukeyTable(classes=as.factor(df$BaseYear[ss]),dependent=df[[varname]][ss],compnames=
c(paste('higher ',varname,sep=''),'no diff.',paste('lower ',varname,sep='')))
return(Tukeytab)
}
comp <- function(year,ttt){
list(which(substr(rownames(ttt),1,4)==as.character(year)),
which (substr(rownames(ttt),6,9)==as.character(year)))}
TukeyTable <- function(classes,dependent,compnames,alpha=0.05){
classes<-droplevels(classes)
#tt<-TukeyHSD(aov(allNDVI[ss]~years.from.baseline.fac[ss]))
tt<-TukeyHSD(aov(dependent~classes))
ttt<-tt$classes
# a function to summarize the output from TukeyHSD
allcomps<-NULL
for(i in levels(classes)){
signif <- c(ttt[comp(i,ttt=ttt)[[1]],4]<alpha,ttt[comp(i,ttt=ttt)[[2]],4]<alpha)
diffs <- c(ttt[comp(i,ttt=ttt)[[1]],1]>0,ttt[comp(i,ttt=ttt)[[2]],1]<0)
newcol <- c(length(which(diffs==T & signif==T)),
length(which(signif==F)),
length(which(diffs==F & signif ==T)))
allcomps<-cbind(allcomps,newcol)}
colnames(allcomps) <- levels(classes)
rownames(allcomps) <- compnames
return(allcomps)}
#+++++++++++ a simple plot for yearly time series +++++++++++++++++####
Simple.plot <- function(CFSR.dat.d.stats,Varname=NULL,minbaseyr=2000,maxbaseyr=2011,maxday=500){
df<-CFSR.dat.d.stats
df<-df[(is.element(df$BaseYear,c(minbaseyr:maxbaseyr))&(df$DOYsinceBase < maxday)),]
require(lattice)
win.graph()
xyplot(get(Varname) ~ DOYsinceBase, data = df,ylab=Varname,lwd=2,
groups = as.factor(BaseYear),type='smooth',span=.3,auto.key=T)
#groups = as.factor(BaseYear),span=.3,auto.key=T)
}
#+++++++++++ calculate daily anomalies per DOY and cellnr for CFSR data +++++++++++++++++####
Daily.anom.stats <- function(CFSR.dat.d,Varname=NULL,minbaseyr=2000,maxbaseyr=2011,maxday=500){
#restrict the data set as requested
df<-CFSR.dat.d
df<-df[(is.element(df$BaseYear,c(minbaseyr:maxbaseyr))&(df$DOYsinceBase < maxday)),]
#calculate the long-term daily means per cell
long.term.daily.mn <- aggregate(df,by=list(substr(df$imdate,6,10),df$cellnrs),FUN=mean)
#convert the observations to anomalies from the long-term cell&day-level means
long.term.daily.mn$DOYsinceBase <- ceiling(long.term.daily.mn$DOYsinceBase)
require(plyr)
df3 <- join(df,long.term.daily.mn,by=c("DOYsinceBase","cellnrs"),type="left",match="first")
#df3 <- df3[,!duplicated(colnames(df3))]
vardf <- df3[,colnames(df3)==Varname]
anomname <- paste(Varname,"_anom",sep="")
anom <- vardf[,1]-vardf[,2]
df[[anomname]]<-anom
return(df)
}
load("C:/Users/sarah/Documents/GitHub/extreme_limits/Mexico_CFSR_level2.rdata")
precip.fac <- 6*60*60
maxDOY<-max(annual.anom.df$DOYsinceBase.y)
rainbowcols<-rainbow(maxDOY*5/4)[1:(maxDOY+1)]
Tukey.cumpre<-plot.CFSR.Annual.var(Prec.dat.d,maxday=150,varname="pre")
Tukey.tmin<-plot.CFSR.Annual.var(Tmin.dat.d,maxday=150,varname="tmin")
Tukey.wnd<-plot.CFSR.Annual.var(Wnd.dat.d,maxday=150,varname="wnd")
Tmin.dat.d <- Daily.anom.stats(Tmin.dat.d,Varname="tmin",minbaseyr=2000,maxbaseyr=2012,maxday=134)
Tukey.tesanom<-plot.CFSR.Annual.var(Tes.dat.d,maxday=134,varname="Tes_anom");abline(h=0)
Tes.dat.d <- Daily.anom.stats(Tes.dat.d,Varname="Tes",minbaseyr=2000,maxbaseyr=2012,maxday=134)
Tukey.tesanom<-plot.CFSR.Annual.var(Tes.dat.d,maxday=134,varname="Tes_anom");abline(h=0)
Prec.dat.d <- Daily.anom.stats(Prec.dat.d,Varname="cumpre",minbaseyr=2000,maxbaseyr=2012,maxday=134)
Tukey.cumpreanom <- plot.CFSR.Annual.var(Prec.dat.d,maxday=150,varname="cumpre_anom");abline(h=0)
Te.dat.d <- Daily.anom.stats(Te.dat.d,Varname="Te",minbaseyr=2000,maxbaseyr=2012,maxday=134)
head(Te.dat.d)
source('~/.active-rstudio-document', echo=TRUE)
Te.dat.d <- Daily.anom.stats(Te.dat.d,Varname="Te",minbaseyr=2000,maxbaseyr=2012,maxday=134)
Tukey.cumpreanom <- plot.CFSR.Annual.var(Te.dat.d,maxday=150,varname="Te_anom");abline(h=0)
annual.anom.df <- join(Tes.dat.d,Prec.dat.d)
annual.anom.df <- join(annual.anom.df,Tmin.dat.d)
annual.anom.df <- join(annual.anom.df,Te.dat.d)
annual.anom.df <- aggregate(annual.anom.df, by=list(annual.anom.df$imdate),FUN=mean)
load("C:/Users/sarah/Documents/GitHub/extreme_limits/data/NDVI_df.rdata")
NDVI.dat<-NDVI.dat[!duplicated(NDVI.dat),]
colnames(NDVI.dat)
#+++++++++++ make 1 smoothed NDVI ts  ++++++++++####
NDVI.dat.daily<-aggregate(NDVI.dat,by=list(NDVI.dat$allDate),FUN=mean)
NDVI.dat.daily$years.from.baseline.fac <- as.factor(NDVI.dat.daily$years.from.baseline)
NDVI.dat.daily$allYEARfac <- as.factor(NDVI.dat.daily$allYEAR)
aqf <- function(x,splinemod=spl) {
zz <- predict(splinemod, x)$y;zz}
win.graph()
plot(NDVI.dat$allDate,NDVI.dat$allNDVI,pch=16,col=rgb(.5,.5,.5,.2),cex=.2,ylab="MODIS (Terra & Aqua) NDVI",
xlab="",main="Vegetation productivity on Broad-tailed Hummingbird wintering grounds",
ylim=c(.4,.9),xlim=as.Date(c())
spl <- smooth.spline(NDVI.dat$allDate,NDVI.dat$allNDVI,df=80)
prednrs <- c(min(spl$x):max(spl$x))
lines(as.Date(prednrs,origin="1970-01-01"),aqf(x=prednrs,splinemod=spl),col="dark green",lwd=2.5)
abline(v=as.Date(paste(c(2001:2013),"-01-01",sep="")),lty=2)
spl2 <- smooth.spline(NDVI.dat.daily$allDate,NDVI.dat.daily$allNDVI,df=80)
#plot(NDVI.dat.daily$allDate,NDVI.dat.daily$allNDVI,pch=16,col="grey",cex=.5)
lines(as.Date(prednrs,origin="1970-01-01"),aqf(x=prednrs,splinemod=spl2),col=4)
smoothNDVIdf <- cbind.data.frame(as.Date(prednrs,origin="1970-01-01"),aqf(x=prednrs,splinemod=spl))
plot(NDVI.dat$allDate,NDVI.dat$allNDVI,pch=16,col=rgb(.5,.5,.5,.2),cex=.2,ylab="MODIS (Terra & Aqua) NDVI",
xlab="",main="Vegetation productivity on Broad-tailed Hummingbird wintering grounds",
ylim=c(.4,.9))#,xlim=as.Date(c())
spl <- smooth.spline(NDVI.dat$allDate,NDVI.dat$allNDVI,df=80)
prednrs <- c(min(spl$x):max(spl$x))
lines(as.Date(prednrs,origin="1970-01-01"),aqf(x=prednrs,splinemod=spl),col="dark green",lwd=2.5)
abline(v=as.Date(paste(c(2001:2013),"-01-01",sep="")),lty=2)
spl2 <- smooth.spline(NDVI.dat.daily$allDate,NDVI.dat.daily$allNDVI,df=80)
#plot(NDVI.dat.daily$allDate,NDVI.dat.daily$allNDVI,pch=16,col="grey",cex=.5)
lines(as.Date(prednrs,origin="1970-01-01"),aqf(x=prednrs,splinemod=spl2),col=4)
smoothNDVIdf <- cbind.data.frame(as.Date(prednrs,origin="1970-01-01"),aqf(x=prednrs,splinemod=spl))
colnames(smoothNDVIdf) <- c("imdate","smoothNDVI")
smoothNDVIdf <- cbind.data.frame(smoothNDVIdf,days.since.base(smoothNDVIdf$imdate,baseline="-11-01"))
smoothNDVIdf[["cellnrs"]]<-rep(-1,nrow(smoothNDVIdf))
smoothNDVIdf <- Daily.anom.stats(smoothNDVIdf,Varname="smoothNDVI",minbaseyr=2000,maxbaseyr=2012,maxday=250)
Tukey.NDVIanom <- plot.CFSR.Annual.var(smoothNDVIdf,maxday=150,varname="smoothNDVI_anom");abline(h=0)
annual.anom.df.backup <- annual.anom.df
head(annual.anom.df)
annual.anom.df<- merge(x=annual.anom.df,y=smoothNDVIdf,FUN=mean,by.x="Group.1",by.y="imdate")
annual.anom.df <- annual.anom.df[(annual.anom.df$BaseYear.x <= 2011)&(annual.anom.df$BaseYear.x >= 2000),]  #CHECK THE ONE-FIFTY NR
save(annual.anom.df, file="C:/Users/sarah/Documents/GitHub/extreme_limits/data/annual.anom.df.rdata")
Simple.plot(smoothNDVIdf,"smoothNDVI",minbaseyr=2002,maxday=250)
Tukey.NDVI<-plot.CFSR.Annual.var(smoothNDVIdf,maxday=150,varname="smoothNDVI")
smoothNDVIdf <- Daily.anom.stats(smoothNDVIdf,Varname="smoothNDVI",minbaseyr=2000,maxbaseyr=2012,maxday=250)
Tukey.NDVI <- plot.CFSR.Annual.var(smoothNDVIdf,maxday=150,varname="smoothNDVI");abline(h=0)
#++++++++++++++++++++ A FUNCTION TO COMPARE 2 VARS BETWEEN ONE YEAR AND THE OTHERS ++++####
BivariateWinterComp<- function(df=annual.anom.df,xvar,yvar,maxDOY=250,focalBaseYr=2010,
Focalpoints=T,PointsLegend=T,focalBag=F,
xlabb=NULL,
ylabb=NULL,
xarrow=c(NA,NA),yarrow=c(NA,NA),legpos="topleft")
{
require(aplpack)
df<-df[df$DOYsinceBase.y<=maxDOY,]
xx<-df[[xvar]];yy<-df[[yvar]]
ss<-df$BaseYear.x==focalBaseYr
bagplot(x=xx[!ss],y=yy[!ss],na.rm=T, xlab=xlabb,ylab=ylabb,
show.outlier=T,show.bagpoints=F,show.looppoints=F,show.whiskers=F,
transparency=T,xlim=range(xx,na.rm=T),ylim=range(yy,na.rm=T),cex=0.4
,col.loophull=grey(.75)
,col.baghull=grey(.5),col.bagpoints=1
)
cat(length(which(ss))," observations in focal year\n")
cat(length(which(!ss))," observations in all other years focal year\n")
if(focalBag){bagplot(x=xx[ss],y=yy[ss],na.rm=T,
show.outlier=F,show.bagpoints=F,show.looppoints=F,show.whiskers=F,
transparency=T,xlim=range(xx,na.rm=T),ylim=range(yy,na.rm=T),cex=0,add=T)}
rainbowcols<-rainbow(maxDOY*5/4)[1:(maxDOY+1)]
if(Focalpoints){
#points(xx[ss],yy[ss],pch=16,col=rainbow(df$DOYsinceBase.y[ss]/maxDOY))
points(xx[ss],yy[ss],pch=16,col=rainbowcols[df$DOYsinceBase.y[ss]+1])
install.packages("aplpack")
#++++++++++++++++++++ A FUNCTION TO COMPARE 2 VARS BETWEEN ONE YEAR AND THE OTHERS ++++####
BivariateWinterComp<- function(df=annual.anom.df,xvar,yvar,maxDOY=250,focalBaseYr=2010,
Focalpoints=T,PointsLegend=T,focalBag=F,
xlabb=NULL,
ylabb=NULL,
xarrow=c(NA,NA),yarrow=c(NA,NA),legpos="topleft")
{
require(aplpack)
df<-df[df$DOYsinceBase.y<=maxDOY,]
xx<-df[[xvar]];yy<-df[[yvar]]
ss<-df$BaseYear.x==focalBaseYr
bagplot(x=xx[!ss],y=yy[!ss],na.rm=T, xlab=xlabb,ylab=ylabb,
show.outlier=T,show.bagpoints=F,show.looppoints=F,show.whiskers=F,
transparency=T,xlim=range(xx,na.rm=T),ylim=range(yy,na.rm=T),cex=0.4
,col.loophull=grey(.75)
,col.baghull=grey(.5),col.bagpoints=1
)
cat(length(which(ss))," observations in focal year\n")
cat(length(which(!ss))," observations in all other years focal year\n")
if(focalBag){bagplot(x=xx[ss],y=yy[ss],na.rm=T,
show.outlier=F,show.bagpoints=F,show.looppoints=F,show.whiskers=F,
transparency=T,xlim=range(xx,na.rm=T),ylim=range(yy,na.rm=T),cex=0,add=T)}
rainbowcols<-rainbow(maxDOY*5/4)[1:(maxDOY+1)]
if(Focalpoints){
#points(xx[ss],yy[ss],pch=16,col=rainbow(df$DOYsinceBase.y[ss]/maxDOY))
points(xx[ss],yy[ss],pch=16,col=rainbowcols[df$DOYsinceBase.y[ss]+1])
#points(xx[ss],yy[ss])
}
if(!is.na(yarrow[1])){
arrows(x0=min(xx,na.rm=T),y0=min(yy,na.rm=T)/3*1,y1=min(yy,na.rm=T)/3*2,length=.1)
mtext(side=2,line=-1,at=max(yy,na.rm=T)/2,text=yarrow[2])
arrows(x0=min(xx,na.rm=T),y0=max(yy,na.rm=T)/3*1,y1=max(yy,na.rm=T)/3*2,length=.1)
mtext(side=2,line=-1,at=min(yy,na.rm=T)/2,text=yarrow[1])
}
if(!is.na(xarrow[1])){
arrows(y0=min(yy,na.rm=T),x0=min(xx,na.rm=T)/3*1,x1=min(xx,na.rm=T)/3*2,length=.1)
mtext(side=1,line=-1,at=max(xx,na.rm=T)/2,text=xarrow[2])
arrows(y0=min(yy,na.rm=T),x0=max(xx,na.rm=T)/3*1,x1=max(xx,na.rm=T)/3*2,length=.1)
mtext(side=1,line=-1,at=min(xx,na.rm=T)/2,text=xarrow[1])
}
#browser()
if(PointsLegend){
levs<-c(0,.2,.4,.6,.8,1)*maxDOY;levs[1]<-levs[1]+1;levs[length(levs)]<-levs[length(levs)]-1
# legend("topright",pch=16,title=paste("Days since 1 Nov ", focalBaseYr,sep=""),col=grey(levs/maxDOY)
#       ,legend=paste(round(levs)," days",sep=""),box.col=NULL,bty="n")
#points(pch=16,-4:0,rep(-0.005,length(levs)),col=rainbowcols[round(levs)])
legend(legpos,pch=16,title=paste("Days since 1 Nov ", focalBaseYr,sep=""),col=rainbowcols[round(levs)]
,legend=paste(round(levs)," days",sep=""),box.col=NULL,bty="n")
#legend("topright",pch=1,paste("Days since 1 Nov ", focalBaseYr,sep=""),
#       ,legend=paste(round(levs)," days",sep=""),bty="n",text.col=NA)
}
box();abline(h=0,lty=1,col="grey");abline(v=0,lty=1,col="grey")
return()
}
win.graph()
BivariateWinterComp(df=annual.anom.df,xvar="Te_anom",yvar="cumpre_anom",maxDOY=134,focalBaseYr=2010,
Focalpoints=T,PointsLegend=T,focalBag=F,
xlabb="Te anomaly (C)",ylabb="Cumulative precipitation anomaly (mm)"
,xarrow=c("colder","warmer")
,yarrow=c("dryer","wetter"))
win.graph()
BivariateWinterComp(df=annual.anom.df,xvar="smoothNDVI_anom",yvar="cumpre_anom",maxDOY=134,focalBaseYr=2010,
Focalpoints=T,PointsLegend=T,focalBag=F,
xlabb="NDVI anomaly",ylabb="Cumulative precipitation anomaly (mm)"
,xarrow=c("less productive","more productive")
,yarrow=c("dryer","wetter"))
win.graph()
BivariateWinterComp(df=annual.anom.df,xvar="smoothNDVI_anom",yvar="Te_anom",maxDOY=134,focalBaseYr=2010,
Focalpoints=T,PointsLegend=T,focalBag=F,
xlabb="NDVI anomaly",ylabb="Te anomaly (C)")
win.graph()
BivariateWinterComp(df=annual.anom.df,xvar="smoothNDVI_anom",yvar="cumpre_anom",maxDOY=134,focalBaseYr=2009,
Focalpoints=T,PointsLegend=T,focalBag=F,
xlabb="NDVI anomaly",ylabb="Cumulative precipitation anomaly (mm)"
,xarrow=c("less productive","more productive")
,yarrow=c("dryer","wetter"))
long.term.daily.mnNDVI <- aggregate(smoothNDVIdf,by=list(substr(smoothNDVIdf$allDate,6,10)),FUN=mean)
long.term.daily.mnNDVI <- aggregate(smoothNDVIdf,by=list(substr(smoothNDVIdf$allDate,6,10)),FUN=mean)
yearly.climdat <- function(tapply.out, nm){
tapply.out <-as.data.frame(tapply.out)
tapply.out <- cbind.data.frame(tapply.out, as.numeric(rownames(tapply.out)))
colnames(tapply.out)[2] <- "yr"
colnames(tapply.out)[1] <- nm
return(tapply.out)
}
yearly.Tes <- tapply(annual.anom.df$Tes, annual.anom.df$BaseYear.x, mean)
yearly.Tes <- yearly.climdat(yearly.Tes,nm="Tes")
yearly.climate <- yearly.Tes
yearly.Tmin <- tapply(annual.anom.df$tmin, annual.anom.df$BaseYear.x, mean)
yearly.Tmin <- yearly.climdat(yearly.Tmin, nm="Tmin")
yearly.climate <- merge(yearly.climate, yearly.Tmin)
Te.10C.quant <- function(x){ 100 * length(which(x <= 10)) / length(x) }
yearly.Te.10C.q <- tapply(annual.anom.df$Te, annual.anom.df$BaseYear.x, Te.10C.quant)
yearly.Te.10C.q <- yearly.climdat(yearly.Te.10C.q,nm = "yearly.Te.10C.q")
yearly.climate <- merge(yearly.climate, yearly.Te.10C.q)
rm(yearly.Te.10C.q)
#what's the 10% quantile?
yearly.Te.10C.quant <- tapply(annual.anom.df$Te, annual.anom.df$BaseYear.x, Te.10C.quant)
Quant10perc <- function(x){quantile(x, probs=0.10)}
yearly.Te.q10 <- tapply(annual.anom.df$Te, annual.anom.df$BaseYear.x, Quant10perc)
yearly.Te.q10 <- yearly.climdat(yearly.Te.q10, nm = "yearly.Te.q10")
yearly.climate <- merge(yearly.climate,yearly.Te.q10)
rm(yearly.Te.q10)
Quant25perc <- function(x){quantile(x, probs=0.25)}
yearly.Te.q25 <- tapply(annual.anom.df$Te, annual.anom.df$BaseYear.x, Quant25perc)
yearly.Te.q25 <- yearly.climdat(yearly.Te.q25, nm="yearly.Te.q25")
yearly.climate <- merge(yearly.climate, yearly.Te.q25)
rm(yearly.Te.q25)
Quant50perc <- function(x){quantile(x, probs=0.5)}
yearly.Te.q50 <- tapply(annual.anom.df$Te, annual.anom.df$BaseYear.x, Quant50perc)
yearly.Te.q50 <- yearly.climdat(yearly.Te.q50, nm="yearly.Te.q50")
yearly.climate <- merge(yearly.climate, yearly.Te.q50)
rm(yearly.Te.q50)
yearly.NDVI <- tapply(annual.anom.df$smoothNDVI, annual.anom.df$BaseYear.x, mean)
yearly.NDVI <- yearly.climdat(yearly.NDVI,nm="NDVI")
yearly.climate <- merge(yearly.climate,yearly.NDVI)
yearly._1NDVI <- yearly.NDVI
yearly._1NDVI$minNDVI <- -1*yearly._1NDVI$NDVI
yearly.climate <- merge(yearly.climate,yearly._1NDVI)
yearly.pre <- tapply(annual.anom.df$pre, annual.anom.df$BaseYear.x, mean) * 60 * 60 * 6
yearly.pre <- yearly.climdat(yearly.pre,nm="pre")
yearly.climate <- merge(yearly.climate,yearly.pre)
#+++++++++++++++++++++++++++++++++++++++++++++++++++++
#+++++++++++++++++++++++++++++++++++++++++++++++++++++
winterend.NDVI <- annual.anom.df[annual.anom.df$DOYsinceBase.x == 133, ]
winterend.NDVI <- tapply(winterend.NDVI$smoothNDVI, winterend.NDVI$BaseYear.x, mean)
winterend.NDVI <- yearly.climdat(winterend.NDVI, nm = "winterNDVI")
yearly.climate <- merge(yearly.climate, winterend.NDVI)
winterend._1NDVI <- winterend.NDVI
winterend._1NDVI$minwinterNDVI <- -1*winterend._1NDVI$winterNDVI
yearly.climate <- merge(yearly.climate, winterend._1NDVI)
winterend.cumpre <- annual.anom.df[annual.anom.df$DOYsinceBase.x == 133, ]
winterend.cumpre <- tapply(winterend.cumpre$cumpre, winterend.cumpre$BaseYear.x, mean)
winterend.cumpre <- yearly.climdat(winterend.cumpre, nm="wintercumpre")
yearly.climate <- merge(yearly.climate, winterend.cumpre)
#the year in yearly.climate denotes the second year of that winter, rather than the
#baseyear !! to conform with the capture data from Arizona !
yearly.climate$yr <- yearly.climate$yr + 1
head(yearly.climate)
yearly.climate2=yearly.climate
load("data/yearly.climate.rdata")
getwd()
setwd("C:/Users/sarah/Documents/GitHub/extreme_limits/")
load("data/yearly.climate.rdata")
head(yearly.climate)
head(yearly.climate2)
yearly.climate=yearly.climate2
save(yearly.climate, file="C:/Users/sarah/Documents/GitHub/extreme_limits/data/yearly.climate.rdata")
pairs(yearly.climate)
attach(yearly.climate,pch=19)
pairs(yearly.climate,pch=19)
attach(yearly.climate)
win.graph()
plot(wintercumallbelow10,winterNDVI,pch=NA)
text(wintercumallbelow10,winterNDVI,yr)
cor.test(wintercumallbelow10,winterNDVI)
cor.test(wintercumallbelow10[yr!=2011],winterNDVI[yr!=2011])
head(yearly.climate)
load("C:/Users/sarah/Dropbox/ActiveResearchProjects/Hummingbird_extreme_limits/data/yearly.catch.stat.rdata")
load("C:/Users/sarah/Documents/GitHub/extreme_limits/data/yearly.catch.stat.rdata")
yearly.catch.stat$sess.quant.05 <- as.Date(yearly.catch.stat$sess.quant.05, origin="2015-01-01")
yearly.catch.stat$sess.quant.25 <- as.Date(yearly.catch.stat$sess.quant.25, origin="2015-01-01")
yearly.catch.stat$sess.quant.50 <- as.Date(yearly.catch.stat$sess.quant.50, origin="2015-01-01")
yearly.catch.stat$sess.quant.75 <- as.Date(yearly.catch.stat$sess.quant.75, origin="2015-01-01")
yearly.catch.stat$sess.quant.95 <- as.Date(yearly.catch.stat$sess.quant.95, origin="2015-01-01")
load("C:/Users/sarah/Documents/GitHub/extreme_limits/data/yearly.climate.rdata")
#gives you yearly.climate
yearly.catch.stat <- merge(yearly.catch.stat, yearly.climate)
require(ggplot2)
#precipitation correlated with NDVI in winter?
ggplot(yearly.climate, aes(wintercumpre, winterNDVI)) + geom_point() + stat_smooth(method="lm") +
ylab("average winter NDVI") + xlab("cumulative winter precip (mm)") + #geom_text(aes(label=yr)) +
theme_classic() + theme(text = element_text(size=20))
lm1 = lm(winterNDVI ~ wintercumpre, data = yearly.climate)
print(summary(lm1)$r.sq)
ggplot(yearly.climate, aes(yearly.Te.10C.q, winterNDVI)) + geom_point() + stat_smooth(method="lm") +
ylab("average winter NDVI") + xlab("percent days with Te < 10 C") + geom_text(aes(label=yr)) +
theme_classic() + theme(text = element_text(size=20))
lm2 = lm(winterNDVI ~ yearly.Te.10C.q, data = yearly.climate)
print(summary(lm2)$r.sq)
srm(yearly.climate)
rm(yearly.climate)
require(lattice)
require(latticeExtra)
xyplot(sess.quant.50 ~ yearly.Te.10C.q|LOC, data=yearly.catch.stat) + layer(panel.smoother(x, y, method = "lm"))
xyplot(sess.quant.50 ~ winterNDVI|LOC, data=yearly.catch.stat) + layer(panel.smoother(x, y, method = "lm"))
source('/Users/sarah/Documents/GitHub/extreme_limits/Model_evaluation_v4.r')
attach(yearly.catch.stat)
#http://www.quantpsy.org/interact/interactions.htm
mod.evaluation(yname='sess.quant.50',centering='CGM',stand=T,log.D=T,R="winterNDVI")
detach(yearly.catch.stat)
attach(yearly.catch.stat)
#http://www.quantpsy.org/interact/interactions.htm
mod.evaluation(yname='sess.quant.25',centering='CGM',stand=T,log.D=T,R="winterNDVI")
detach(yearly.catch.stat)
library(ggplot2)
#load the Hummingbird data; i.e. the d.f. site.dat
load("C:/Users/sarah/Documents/GitHub/extreme_limits/data/site.dat.rdata")
#keep only the variables you need
site.dat <- site.dat[, c("LOC", "PriMary.Molt", "yearfac", "mofac")]
#make an ordered categorical variable describing primary molt
ordermolt <- function(x){ordered(x, levels=c("M","R",1:8,0,9,"F","L"))}
site.dat$PriMary.Molt <- ordermolt(site.dat$PriMary.Molt)
hist(as.numeric(site.dat$PriMary.Molt),col="grey80", xlim = c(0,14), breaks = seq(0.5,14.5, by=1), main = "Primary Molt")
#plot molt stage by year for comparison
sd <- site.dat[complete.cases(site.dat),]
ggplot(sd, aes(PriMary.Molt)) + geom_histogram() + facet_wrap(~yearfac) + theme_bw()
getMOLTquant <- function(quantile.){
tapply(site.dat$PriMary.Molt, INDEX=list(site.dat$LOC, site.dat$yearfac),
FUN=quantile, type=1, probs=c(quantile.), na.rm=T)}
MOLT.quant.05 <- ordermolt(levels(site.dat$PriMary.Molt)[as.vector(getMOLTquant(.05))])
MOLT.quant.25 <- ordermolt(levels(site.dat$PriMary.Molt)[as.vector(getMOLTquant(.25))])
MOLT.quant.50 <- ordermolt(levels(site.dat$PriMary.Molt)[as.vector(getMOLTquant(.50))])
MOLT.quant.75 <- ordermolt(levels(site.dat$PriMary.Molt)[as.vector(getMOLTquant(.75))])
MOLT.quant.95 <- ordermolt(levels(site.dat$PriMary.Molt)[as.vector(getMOLTquant(.95))])
MOLT.quants <- cbind.data.frame(MOLT.quant.05, MOLT.quant.25, MOLT.quant.50, MOLT.quant.75, MOLT.quant.95)
rm(MOLT.quant.05, MOLT.quant.25, MOLT.quant.50, MOLT.quant.75, MOLT.quant.95)
quant.temp <- tapply(site.dat$PriMary.Molt, INDEX=list(site.dat$LOC, site.dat$yearfac),
FUN=quantile, type=1, probs=c(.05), na.rm=T)
LOC <- rownames(quant.temp)
yr <- rep(colnames(quant.temp), each=length(LOC))
rm(quant.temp)
# calculate the nr of birds in each sample ('n.birds')
n.birds <- as.vector(tapply(site.dat$PriMary.Molt, INDEX=list(site.dat$LOC, site.dat$yearfac),
FUN=function(x){length(which(!is.na(x)))}))
#save the new metrics in the d.f. "MOLT.quants"
MOLT.quants <- cbind.data.frame(LOC, yr, n.birds, MOLT.quants)
rm(n.birds, LOC, yr)
load("C:/Users/sarah/Documents/GitHub/extreme_limits/data/yearly.climate.rdata")
#gives you yearly.climate
yearly.molt.stat <- merge(x=MOLT.quants,y=yearly.climate,by='yr')
rm(MOLT.quants,yearly.climate)
require(lattice)
require(latticeExtra)
xyplot(MOLT.quant.50 ~ yearly.Te.10C.q|LOC, data=yearly.molt.stat) + layer(panel.smoother(x, y, method = "lm"))
xyplot(MOLT.quant.50 ~ winterNDVI|LOC, data=yearly.molt.stat) + layer(panel.smoother(x, y, method = "lm"))
source('C:/Users/sarah/Documents/GitHub/extreme_limits/Model_evaluation_v4.r')
attach(yearly.molt.stat)
#http://www.quantpsy.org/interact/interactions.htm
mod.evaluation(yname='MOLT.quant.50', centering='CGM', stand=T, ordered.fac.treatment = "as.binomial",
log.D=T, R="winterNDVI", D="yearly.Te.10C.q")
detach(yearly.molt.stat)
attach(yearly.molt.stat)
#http://www.quantpsy.org/interact/interactions.htm
mod.evaluation(yname='MOLT.quant.25', centering='CGM', stand=T, ordered.fac.treatment = "as.binomial",
log.D=T, R="winterNDVI", D="yearly.Te.10C.q")
detach(yearly.molt.stat)
detach(yearly.molt.stat)
attach(yearly.catch.stat)
mod.evaluation(yname='sess.quant.50',centering='CGM',stand=T,log.D=T,R="winterNDVI")
mod.evaluation(yname='sess.quant.25',centering='CGM',stand=T,log.D=T,R="winterNDVI")
detach(yearly.catch.stat)
attach(yearly.molt.stat)
#http://www.quantpsy.org/interact/interactions.htm
mod.evaluation(yname='MOLT.quant.50', centering='CGM', stand=T, ordered.fac.treatment = "as.binomial",
log.D=T, R="winterNDVI", D="yearly.Te.10C.q")
mod.evaluation(yname='MOLT.quant.25', centering='CGM', stand=T, ordered.fac.treatment = "as.binomial",
log.D=T, R="winterNDVI", D="yearly.Te.10C.q")
detach(yearly.molt.stat)
load("C:/Users/sarah/Documents/GitHub/extreme_limits/data/site.dat.rdata")
site.dat$Fat[site.dat$Fat=="P"] <- 0
orderfat <- function(x){ordered(x, levels=c(0, "T" ,1:3))}
site.dat$Fat <- orderfat(site.dat$Fat)
plot(site.dat$Weight ~ site.dat$Fat, col="light grey", xlab = "Fat", ylab = "Weight",
pch=19, cex.axis = 2, cex.lab = 2)
ordermolt <- function(x){ordered(toupper(x), levels=c("M","R",1:8,0,9,"F","L"))}
site.dat$PriMary.Molt <- ordermolt(site.dat$PriMary.Molt)
plot(site.dat$Weight ~ site.dat$PriMary.Molt, col="light grey", pch=19,
xlab = "Primary Molt", ylab = "Weight", cex.axis = 2, cex.lab = 2)
table(site.dat$PriMary.Molt)
tt<-round(sort(TukeyHSD(aov(site.dat$Weight ~ site.dat$PriMary.Molt))[[1]][,4]), 3)
tt[tt<0.2]
site.dat$Secondary.Molt <- ordermolt(site.dat$Secondary.Molt)
plot(site.dat$Weight ~ site.dat$Secondary.Molt, col="light grey", xlab = "Secondary Molt Class", ylab = "Weight",
, cex.axis = 2, cex.lab = 2, pch=19)
table(site.dat$Secondary.Molt)
tt<-round(sort(TukeyHSD(aov(site.dat$Weight ~ site.dat$Secondary.Molt))[[1]][,4]), 3)
tt[tt<.2]
site.dat$Body.Molt <- ordermolt(site.dat$Body.Molt)
plot(site.dat$Weight ~ site.dat$Body.Molt, col="light grey", xlab="Body Molt Class", ylab="Weight", pch=19,
cex.lab = 2, cex.axis = 2)
table(site.dat$Body.Molt)
tt<-round(sort(TukeyHSD(aov(site.dat$Weight ~ site.dat$Body.Molt))[[1]][,4]),3)
tt[tt<.2]
site.dat$Gorget.head.molt <- ordermolt(site.dat$Gorget.head.molt)
plot(site.dat$Weight ~ site.dat$Gorget.head.molt, col="light grey",xlab="gorget head molt", ylab="Weight", pch=19,
cex.lab = 2, cex.axis = 2)
table(site.dat$Gorget.head.molt)
tt<-round(sort(TukeyHSD(aov(site.dat$Weight ~ site.dat$Gorget.head.molt))[[1]][,4]),3)
tt[tt<.2]
site.dat$Tail.Molt <- ordermolt(site.dat$Tail.Molt)
plot(site.dat$Weight ~ site.dat$Tail.Molt, col="light grey", xlab="tail molt", ylab="Weight", pch=19,
cex.lab = 2, cex.axis = 2)
table(site.dat$Tail.Molt)
tt<-round(sort(TukeyHSD(aov(site.dat$Weight ~ site.dat$Tail.Molt))[[1]][,4]),3)
tt[tt<.2]
site.dat <- site.dat[,c("LOC", "Weight", "Fat", "yearfac", "mofac")]
load("C:/Users/sarah/Documents/GitHub/extreme_limits/data/yearly.climate.rdata")
#gives you yearly.climate
yearly.weight.stat <- merge(x=site.dat, y=yearly.climate, by.x='yearfac', by.y='yr')
rm(site.dat, yearly.climate)
require(lattice)
require(latticeExtra)
xyplot(Weight ~ yearly.Te.10C.q|LOC, data=yearly.weight.stat) + layer(panel.smoother(x, y, method = "lm"))
xyplot(Weight ~ winterNDVI|LOC, data=yearly.weight.stat) + layer(panel.smoother(x, y, method = "lm"))
xyplot(Fat ~ yearly.Te.10C.q|LOC, data=yearly.weight.stat) + layer(panel.smoother(x, y, method = "lm"))
xyplot(Fat ~ winterNDVI|LOC, data=yearly.weight.stat) + layer(panel.smoother(x, y, method = "lm"))
source('C:/Users/sarah/Documents/GitHub/extreme_limits/Model_evaluation_v4.r')
attach(yearly.weight.stat)
#http://www.quantpsy.org/interact/interactions.htm
mod.evaluation(yname='Weight', centering='CGM', stand=T, ordered.fac.treatment = "as.num", log.D=T,
R="winterNDVI", D="yearly.Te.10C.q", N=NULL)
mod.evaluation(yname='Fat', centering='CGM', stand=T, ordered.fac.treatment = "as.num", log.D=T,
R="winterNDVI", D="yearly.Te.10C.q", N=NULL)
datpath <- "/Users/sarah/Documents/github/extreme_limits/data/"
load(paste(datpath, "annual.anom.df.rdata", sep=""))
precip.fac <- 6 * 60 * 60 ######## I can't trace where this scaling of the precip comes from, please double-check if the plotted values make sense!
maxDOY <- max(annual.anom.df$DOYsinceBase.y)
rainbowcols <- rainbow(maxDOY * 5 / 4)[1:(maxDOY + 1)]
plot(annual.anom.df$cumpre * precip.fac, annual.anom.df$smoothNDVI.x,
ylim=range(annual.anom.df$smoothNDVI.x) * c(.97,1),
xlab = "Cumulative precipitation [mm]", ylab = "Normalized Difference Vegetation Index",
pch = 16, col = rainbowcols[annual.anom.df$DOYsinceBase.y + 1], cex = 0.75)
head(annual.anom.df)
range(annual.anom.df$smoothNDVI.x)
range(annual.anom.df$smoothNDVI.x,na.rm=T)
rangeNDVI = sort(annual.anom.df$smoothNDVI.x)
head(range(NDVI))
head(rangeNDVI)
plot(annual.anom.df$cumpre * precip.fac, annual.anom.df$smoothNDVI.x,
ylim=range(0.5,0.65) * c(.97,1),
xlab = "Cumulative precipitation [mm]", ylab = "Normalized Difference Vegetation Index",
pch = 16, col = rainbowcols[annual.anom.df$DOYsinceBase.y + 1], cex = 0.75)
plot(annual.anom.df$cumpre * precip.fac, annual.anom.df$smoothNDVI.x,
ylim=range(0.5,0.9) * c(.97,1),
xlab = "Cumulative precipitation [mm]", ylab = "Normalized Difference Vegetation Index",
pch = 16, col = rainbowcols[annual.anom.df$DOYsinceBase.y + 1], cex = 0.75)
yearly.end.NDVI.vals <- NULL
labs <- c("'00-'01","'01-'02","'02-'03","'03-'04","'04-'05","'05-'06","'06-'07",
"'07-'08","'08-'09","'09-'10","'10-'11","'11-'12")
aa <- 0
for (a in unique(annual.anom.df$BaseYear.y))
{
aa <- aa + 1
lines(precip.fac * annual.anom.df$cumpre[annual.anom.df$BaseYear.y == a],
annual.anom.df$smoothNDVI.x[annual.anom.df$BaseYear.y == a], col="dark grey")
ss <- (annual.anom.df$BaseYear.y == a) & (annual.anom.df$DOYsinceBase.y == 133)
#add labels for particular years
text(precip.fac * annual.anom.df$cumpre[ss] - 14, annual.anom.df$smoothNDVI.x[ss] - 0.007,
labs[aa], cex=1.05, font=2)
end.NDVI.val <- annual.anom.df$smoothNDVI.x[ss]
yearly.end.NDVI.vals <- c(yearly.end.NDVI.vals, end.NDVI.val)
}
